{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Methods for Homework 2, Team 2\n",
    "## DSC291 - Data Science for Scientists and Engineers\n",
    "\n",
    "This notebook demonstrates how we use aws-jupyter to \n",
    "- automatically start EC2 instances of different types\n",
    "- run the same timed script on all these instances\n",
    "- retrieve the results from all instances\n",
    "- and combine all results with pricing data to compare the performance of different instances\n",
    "\n",
    "While this notebook does not describe our actual experiment (we're submitting another one for that), it is meant as a general desription of how it is possible to use aws-jupyter to run any such experiment. \n",
    "\n",
    "**Run the last cell to turn this notebook into a presentation!**\n",
    "\n",
    "*Note: To successfully run this notebook, it's easiest to start it in the conda environment for packages availability.*\n",
    "\n",
    "    $conda activate\n",
    "$jupyter notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# import stuff\n",
    "from os.path import isfile,isdir\n",
    "from os import mkdir,chdir,getcwd\n",
    "import pickle as pk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from time import sleep\n",
    "import argparse\n",
    "\n",
    "# enable inline graphics\n",
    "%pylab inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### We start by listing the instances that are active on our account. \n",
    "This can be helpful, to monitor whether there are any unused instances that are still running, and costing us money.\n",
    "\n",
    "(also, we still haven't been given access to https://ets-apps.ucsd.edu/dsc291-custom-aws/index.cgi, so this is our solution to try to make sure that our costs are not piling up...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!aws ec2 describe-instances \\\n",
    "    --query 'Reservations[*].Instances[*].{Type:InstanceType,\\\n",
    "                                           LaunchTime:LaunchTime,\\\n",
    "                                           Instance:InstanceId,\\\n",
    "                                           KeyName:KeyName,\\\n",
    "                                           State:State.Name,\\\n",
    "                                           Name:Tags[?Key==`cluster-name`]|[0].Value}' \\\n",
    "    --output table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Here are a few options for stopping or terminating instances \n",
    "This one is just an example for if one notices any instances that seem to have been running for a while whithout usage. In that case we can uncomment a line and terminate/stop them manually by their instance ID. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# !aws ec2 stop-instances --instance-ids \"i-0105aaca12dbcb0e1\" \"i-0f36f5a941f2fee32\"\n",
    "# !aws ec2 stop-instances --instance-ids \"i-0c71d929d331d1a9d\" --hibernate\n",
    "# !aws ec2 terminate-instances --instance-ids \"i-06db20077a6e44cad\"\n",
    "# !aws ec2 terminate-instances --instance-ids \"i-0e4ccb193e3cdcdc8\" \"i-03e1edfe2e3dfbebe\" \"i-097fb433d4ae7cbf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Now let's import some data on which instance types are available, and how much they cost.\n",
    "We will use a subset of the instanceType list to start multiple EC2 instances which we want to compare. We will use the pricing data later on, to compare performance to pricing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pricedf = pd.read_csv('ec2ondemandprices20200419.csv')\n",
    "pricedf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here, we are making price column numeric. Then, for this initial test we select only the cheapest instances, to prevent spending too much money on something that might not work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "if pricedf['priceHour'].dtype == 'O':\n",
    "    pricedf['priceHour'] = pd.to_numeric(pricedf.priceHour.str.extract('(\\d*\\.?\\d.?\\d.?\\d.)')[0])\n",
    "\n",
    "priceCutOff = 0.5\n",
    "dfTest = pricedf[pricedf['priceHour'] < priceCutOff]\n",
    "\n",
    "typeList = dfTest['instanceType'].tolist()\n",
    "priceList = np.round(dfTest['priceHour'].tolist(),4)\n",
    "print(typeList)\n",
    "print(priceList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### We'll have to set up each instance before running our test\n",
    "Here, we are creating a script that we will run on each instance to set it up. (This is basically copy-pasted from the class materials.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "startup_script = '''git clone https://github.com/fliphilipp/Public-DSC291\n",
    "sudo pip install psutil\n",
    "\n",
    "# run the following if the instance has an SSD that needs to be formatted and mounted.\n",
    "\n",
    "lsblk\n",
    "sudo mkfs.ext4 -E nodiscard -m0 /dev/nvme0n1   #format\n",
    "sudo mkdir /home/ubuntu/spda                   #make root for mounting\n",
    "sudo mount -o discard /dev/nvme0n1 /home/ubuntu/spda # mount\n",
    "ln -s /home/ubuntu/spda scratch                #create local link\n",
    "sudo chmod a+rwx scratch                       # make read/write-able\n",
    "lsblk'''\n",
    "\n",
    "theFile = open('startup.sh','w') \n",
    "theFile.write(startup_script) \n",
    "theFile.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# make sure this worked\n",
    "!cat startup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Python wrapper for aws-jupyter\n",
    "To use aws-jupyter effectively from a notebook, we are adding some code that makes it easier to run commands from here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def run_command(command,debug=False):\n",
    "    if debug:\n",
    "        print('running ',command)\n",
    "    p=subprocess.Popen(command.split(), stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    out=p.communicate()\n",
    "    stdout=out[0].decode()\n",
    "    stderr=out[1].decode()\n",
    "    outputs={\"stderr\":stderr,\n",
    "             \"stdout\":stdout}\n",
    "    if debug:\n",
    "        print(outputs)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class aws_jupyter:\n",
    "    \"\"\"\n",
    "    A python wrapper around the script **aws-jupyter**\n",
    "    \"\"\"\n",
    "    \n",
    "    def check(self):\n",
    "        \"\"\"\n",
    "        Check on the status of the ec2 instance\n",
    "        Returns status\n",
    "        -------\n",
    "        0 = No instance running under this name \n",
    "        \n",
    "        1 = instance in the process of starting up\n",
    "        \n",
    "        2 = instance available        \n",
    "        \n",
    "        -1 = Status could not be parsed\n",
    "        \"\"\"\n",
    "        check_cmd = \"aws-jupyter check --name %s\"%self.name\n",
    "        self.decoded=run_command(check_cmd)\n",
    "        stdout=self.decoded['stdout']\n",
    "        if('The Jupyter Notebook is running on the cluster at the address below.' in stdout):\n",
    "            print(stdout)\n",
    "            return 2\n",
    "        elif(\"No instance found in the cluster\" in stdout):\n",
    "            return 0\n",
    "        elif(\"Cluster is not ready. Please check again later.\" in stdout):\n",
    "            return 1\n",
    "        else:\n",
    "            print(\" ...did not recognize check status\")\n",
    "            # print(stdout)\n",
    "            return -1\n",
    "\n",
    "    def run(self,scriptname,files=[],credentials=\"\",waitforoutput=True,printoutput=False): \n",
    "        \"\"\"\n",
    "        Run a local script on the remote instance\n",
    "        Parameters\n",
    "        ----------\n",
    "        scriptname : TYPE\n",
    "            DESCRIPTION.\n",
    "        files : TYPE, optional\n",
    "            DESCRIPTION. The default is [].\n",
    "        credentials : TYPE\n",
    "            DESCRIPTION.\n",
    "        waitforoutput : TYPE, optional\n",
    "            DESCRIPTION. The default is True.\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "        \"\"\"\n",
    "            \n",
    "        running_cmd = \"aws-jupyter run -s {script}\"\n",
    "        runcmd = running_cmd.format(script=scriptname)\n",
    "        if len(files)>0:\n",
    "            runcmd += \" --files\"\n",
    "            for i in range(len(files)):\n",
    "                runcmd += \" {fn}\".format(fn=files[i])\n",
    "        if waitforoutput:\n",
    "            runcmd += \" --output\"\n",
    "        print(\"running command: {runcmd}\".format(runcmd=runcmd))\n",
    "        out = run_command(runcmd,debug=False)\n",
    "        if printoutput:\n",
    "            print(out['stdout'])\n",
    "            print(out['stderr'])\n",
    "\n",
    "    def retrieve():\n",
    "        \"\"\" call aws-jupyter retrieve\"\"\"\n",
    "        return\n",
    "    \n",
    "    def terminate(self,printoutput=False):\n",
    "        \"\"\" call aws-jupyter terminate\"\"\"\n",
    "        term_cmd = \"yes | aws-jupyter terminate --name %s\" % self.name\n",
    "        print(\"terminate instance: {term_cmd}\".format(term_cmd=term_cmd))\n",
    "        out = run_command(term_cmd)\n",
    "        if printoutput:\n",
    "            print(out['stdout'])\n",
    "            print(out['stderr'])\n",
    "            \n",
    "    def __init__(self,name='instance',count=1,_type='t3.large',spot=0):\n",
    "        \"\"\"\n",
    "        Create a cluster of instances on ec2\n",
    "        Parameters\n",
    "        ----------\n",
    "        name : TYPE, optional\n",
    "            DESCRIPTION. The default is 'instance'.\n",
    "        count : TYPE, optional\n",
    "            DESCRIPTION. The default is 1.\n",
    "        _type : TYPE, optional\n",
    "            DESCRIPTION. The default is 't3.large'.\n",
    "        spot : TYPE, optional\n",
    "            DESCRIPTION. The default is 0.\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "        \"\"\"\n",
    "        self.name=name\n",
    "        status=self.check()\n",
    "        if status==1:\n",
    "            print(\"cluster %s not ready yet\"%self.name)\n",
    "            return\n",
    "        elif status==2:\n",
    "            print(\"cluster running\")\n",
    "            return\n",
    "\n",
    "        create_cmd = \"aws-jupyter create -c {count} --name {name} --type {_type}\"\n",
    "        command=create_cmd.format(count=count,name=name,_type=_type)\n",
    "        if spot>0:\n",
    "            command.append(\" --spot %4.2f\"%spot)\n",
    "        out=run_command(command)\n",
    "        print(\"initiated instance:\",command)\n",
    " \n",
    "        i=0; wait_period=10\n",
    "        while True:\n",
    "            status=self.check()\n",
    "            if status==2:\n",
    "                # print(stdout)\n",
    "                break\n",
    "            print('\\r check',i*wait_period,end='')\n",
    "            i+=1\n",
    "            sleep(wait_period)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Jake]: This is where we can run the scripts I wrote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for typeL in typeList:\n",
    "    \n",
    "    # Create an instance of typeL\n",
    "    print(\"Creating instance %s\"%typeL)\n",
    "    !aws-jupyter create -c 1 -t $typeL --name $typeL\n",
    "    time.sleep(30) # wait for aws to configure the instance\n",
    "    output = subprocess.Popen(\"aws-jupyter check --name %s\"%typeL, shell=True, stdout=subprocess.PIPE).communicate()\n",
    "    print(\"\\t...done\")\n",
    "    \n",
    "    ## The below directory should be the git repository. the remote directory \"./\" is \"/home/ubuntu/hw2\" on the AWS system\n",
    "    check_file_send = subprocess.Popen('aws-jupyter send-dir --local /home/jakemdaly/Documents/courses/dsc-291/TeamGitRepo/Public-DSC291/hw2/ --remote ./', shell=True, stdout=subprocess.PIPE).communicate()\n",
    "    print(f\"Sent local directory to instance\")\n",
    "    \n",
    "    # Now we need to find out what the IP address of the cluster is\n",
    "    start_char = str(output).find(\"ubuntu\")\n",
    "    indexer = start_char\n",
    "    while str(output)[indexer] != \" \":\n",
    "        indexer += 1\n",
    "    remote_instance = str(output)[start_char:indexer]\n",
    "    \n",
    "    \n",
    "    print(f\"Remote instance: {remote_instance}\")\n",
    "    print(\"Running the file generator and measuring latencies...\")\n",
    "    check1 = subprocess.Popen(\"ssh -i /home/jakemdaly/.ssh/JakeTeam2KeyPair.pem %s 'pip install s3cmd; cd hw2; /home/ubuntu/.local/bin/s3cmd get s3://jakes-bucket-dsc-291/*.csv . --access_key=AKIAR4UELFPSEPNDEM5R --secret_key=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 --region us-west-2 --force; /usr/bin/python3 TestLatencies.py'\"%remote_instance, shell=True, stdout=subprocess.PIPE).communicate()\n",
    "    print(\"\\t...done\")\n",
    "    print(\"Copying .csv files to local directory and terminating notebook\")\n",
    "    check2 = subprocess.Popen(\"scp -i /home/jakemdaly/.ssh/JakeTeam2KeyPair.pem %s:/home/ubuntu/hw2/latencies.csv /home/jakemdaly/Documents/courses/dsc-291/TeamGitRepo/Public-DSC291/hw2/\"%remote_instance, shell=True, stdout=subprocess.PIPE).communicate()\n",
    "    check3 = subprocess.Popen(\"mv latencies.csv latencies_%s.csv\"%(typeL), shell=True, stdout=subprocess.PIPE).communicate()\n",
    "    check4 = subprocess.Popen(\"aws-jupyter terminate --name %s\"%typeL, shell=True).communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure all the instances are closed.\n",
    "for typeL in typeList:\n",
    "    subprocess.call(\"aws-jupyter terminate --name %s\"%typeL, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A test script to run on each instance\n",
    "\n",
    "Here, we are defining a test script that we will be running on each instance. The calculations to be done are timed a hundred times, and the results are written to a pickle file. \n",
    "\n",
    "For this test, we are just running a quick and simple task (finding the 100,000th Fibonacci number recursively). For our actual experiment, this script is more involved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "program_to_run = '''#!/usr/bin/env python3\n",
    "\n",
    "import numpy as np\n",
    "from time import time\n",
    "from os.path import isfile,isdir\n",
    "from os import mkdir,chdir,getcwd\n",
    "import pickle as pk\n",
    "\n",
    "times = []\n",
    "nTrials = 100\n",
    "nFibonacci = 10**5\n",
    "\n",
    "# a dumb random computational task, on which to compare instances\n",
    "inst_starttime = time()\n",
    "for k in range(nTrials):\n",
    "    starttime = time()\n",
    "    fibonacci_previous = 1\n",
    "    fibonacci_current = 1\n",
    "    for i in range(2,nFibonacci):\n",
    "        fibonacci_next = fibonacci_previous + fibonacci_current\n",
    "        fibonacci_previous = fibonacci_current\n",
    "        fibonacci_current = fibonacci_next\n",
    "    DT = time() - starttime\n",
    "    times.append(DT)\n",
    "print(time() - inst_starttime)\n",
    "    \n",
    "#hist(times,bins=50)\n",
    "exec_dir = getcwd()\n",
    "log_dir = exec_dir + '/measurement_logs/'\n",
    "if not isdir(log_dir):\n",
    "    mkdir(log_dir)\n",
    "fn = log_dir + 'stats.pkl'\n",
    "with open(fn,'wb') as times_pkl:\n",
    "    pk.dump(times,times_pkl,protocol=pk.HIGHEST_PROTOCOL)'''\n",
    "\n",
    "theFile = open('ec2testFibonacci.py','w') \n",
    "theFile.write(program_to_run) \n",
    "theFile.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Before we start, let's check which instances we will actually be using.\n",
    "We can also further make the list shorter here, if we are just trying to see if this notebook works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# if you want to just try, say, 3 different ones for testing\n",
    "# typeList = typeList[0:3]\n",
    "typeList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Now lets start all instances in the list and run our timed experiment multiple times!\n",
    "This is where things actually happen. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# create a directory in which we will collect test results from different instance types\n",
    "remotedir = 'from_remote'\n",
    "if not isdir(remotedir):\n",
    "    mkdir(remotedir)\n",
    "\n",
    "# now loop through all instance types that we want to test, and actually run the test on them\n",
    "for thisType in typeList:\n",
    "    thisName = \"h2\" + thisType.replace('.','')\n",
    "    \n",
    "    # initiate instance and run startup\n",
    "    thisInst = aws_jupyter(name=thisName, count=1, _type=thisType)\n",
    "    thisInst.run(scriptname='startup.sh',printoutput=True)\n",
    "    \n",
    "    # run the test script\n",
    "    thisInst.run(scriptname='ec2testFibonacci.py',printoutput=True)\n",
    "    \n",
    "    # retrieve files\n",
    "    !sleep 120\n",
    "    !aws-jupyter retrieve --remote /home/ubuntu/workspace/measurement_logs/stats.pkl --local from_remote/\n",
    "    new_fn = 'from_remote/stats_' + thisType.replace('.','-') + '.pkl'\n",
    "    !mv from_remote/worker-0/stats.pkl $new_fn\n",
    "    \n",
    "    # terminate instances\n",
    "    # thisInst.terminate(printoutput=True)  # <--- somehow this doesn't work!\n",
    "    !yes | aws-jupyter terminate --name $thisInst.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Print out a list of our instances again\n",
    "To make sure we've terminated them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# , to make sure we've terminated them\n",
    "!aws ec2 describe-instances \\\n",
    "    --query 'Reservations[*].Instances[*].{Type:InstanceType,\\\n",
    "                                           LaunchTime:LaunchTime,\\\n",
    "                                           Instance:InstanceId,\\\n",
    "                                           KeyName:KeyName,\\\n",
    "                                           State:State.Name,\\\n",
    "                                           Name:Tags[?Key==`cluster-name`]|[0].Value}' \\\n",
    "    --output table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Now, get all the collected data back into this notebook\n",
    "Here, we create a pandas dataframe with all the data collected from the different types of instances. We need to collect the data from all the different files that were sent back to us from the different instances we've created.\n",
    "\n",
    "We can print the first few lines of the dataframe to see if the data looks about right. \n",
    "\n",
    "*Here, something must have gone wrong on the instance of type **c5.large** that we had created. The output logs (which were deleted because they contained our AWS credentials) seem to indicate that the ssh connection failed when trying to retrieve the file with the results.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns = typeList)\n",
    "for thisType in typeList:\n",
    "    filename = 'from_remote/stats_' + thisType.replace('.','-') + '.pkl'\n",
    "    if isfile(filename):\n",
    "        infile = open(filename,'rb')\n",
    "        thisData = pk.load(infile)\n",
    "        infile.close()\n",
    "        results[thisType] = thisData\n",
    "\n",
    "# display the top of the dataframe\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Now, we can finally examine the data!\n",
    "Here, we are just creating a boxplot of the execution times by instance type. We see that the (cheap) instances that we tested all needed on average between 0.12 to 0.24 seconds to determine the 100,00th Fibonacci number recursively. The fastest instance types here are the compute optimized **c5.xlarge** and **c5.2xlarge**, and the memory optimized **r5d.xlarge**. \n",
    "\n",
    "Not surprisingly, these faster instances were also some of the comparatively more expensive ones amongst our set of types. So is it actually worth it paying that higher price to cut the execution time down?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bp1 = results.boxplot(rot=90)\n",
    "bp1.set_title('execution times on different instance types')\n",
    "bp1.set_ylabel('execution time in seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cost-effectiveness\n",
    "Here, we multiply the time the computations took by the hourly price of the instance to see how much the computation actually cost us on each type of instance. *(the numbers are very low, since all prices were <$0.50/hr and computation times were less than a second...)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "byPrice = pd.DataFrame(columns = typeList)\n",
    "for i, thisType in enumerate(typeList):\n",
    "    byPrice[thisType] = priceList[i] * (results[thisType] / 3600)\n",
    "byPrice.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Now let's see how adjusting by price changes our perception of instance performance!\n",
    "Now we see that for the same task, <span style=\"color:red\">the least powerful instance types were actually much more efficient</span> than the more powerful ones in terms of total cost!\n",
    "\n",
    "So, if you have a lot of time and are really just interested in recursively calculating Fibonacci numbers, then you should do so on a **t3.nano** instance! \n",
    "\n",
    "We assume that this price effectiveness will change when you do more complex tasks, such as moving large files between S3 and EC2 instances. This is why the second notebook in our submission for homework 2 is testing this scenario, focussing more on the analysis of the results than on the methods of how to get things running. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bp2 = byPrice.boxplot(rot=90)\n",
    "bp2.set_title('cost-effectiveness of different instance types')\n",
    "bp2.set_ylabel('price for execution time of the script')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# To view this notebook as slides\n",
    "!jupyter nbconvert hw2psa.ipynb --to slides --post serve"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
