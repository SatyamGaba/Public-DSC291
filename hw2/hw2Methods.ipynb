{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Methods for Homework 2, Team 2\n",
    "## DSC291 - Data Science for Scientists and Engineers\n",
    "\n",
    "This notebook demonstrates how we use aws-jupyter to \n",
    "- automatically start EC2 instances of different types\n",
    "- run the same timed script on all these instances\n",
    "- retrieve the results from all instances\n",
    "- and combine all results with pricing data to compare the performance of different instances\n",
    "\n",
    "While this notebook does not describe our actual experiment (we're submitting another one for that), it is meant as a general desription of how it is possible to use aws-jupyter to run any such experiment. \n",
    "\n",
    "**Run the last cell to turn this notebook into a presentation!**\n",
    "\n",
    "*Note: To successfully run this notebook, it's easiest to start it in the conda environment for packages availability.*\n",
    "\n",
    "    $conda activate\n",
    "$jupyter notebook\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:hw2/.ipynb_checkpoints/hw2PhilippFirstTry-checkpoint.ipynb
   "execution_count": null,
=======
   "execution_count": 2,
>>>>>>> 2ec9f9959224f60d8f7ccfb3db3641004d4e7a55:hw2/hw2Methods.ipynb
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# import stuff\n",
    "from os.path import isfile,isdir\n",
    "from os import mkdir,chdir,getcwd\n",
    "import pickle as pk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from time import sleep\n",
    "import argparse\n",
    "\n",
    "# enable inline graphics\n",
    "%pylab inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### We start by listing the instances that are active on our account. \n",
    "This can be helpful, to monitor whether there are any unused instances that are still running, and costing us money.\n",
    "\n",
    "(also, we still haven't been given access to https://ets-apps.ucsd.edu/dsc291-custom-aws/index.cgi, so this is our solution to try to make sure that our costs are not piling up...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!aws ec2 describe-instances \\\n",
    "    --query 'Reservations[*].Instances[*].{Type:InstanceType,\\\n",
    "                                           LaunchTime:LaunchTime,\\\n",
    "                                           Instance:InstanceId,\\\n",
    "                                           KeyName:KeyName,\\\n",
    "                                           State:State.Name,\\\n",
    "                                           Name:Tags[?Key==`cluster-name`]|[0].Value}' \\\n",
    "    --output table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Here are a few options for stopping or terminating instances \n",
    "This one is just an example for if one notices any instances that seem to have been running for a while whithout usage. In that case we can uncomment a line and terminate/stop them manually by their instance ID. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# !aws ec2 stop-instances --instance-ids \"i-0105aaca12dbcb0e1\" \"i-0f36f5a941f2fee32\"\n",
    "# !aws ec2 stop-instances --instance-ids \"i-0c71d929d331d1a9d\" --hibernate\n",
    "# !aws ec2 terminate-instances --instance-ids \"i-06db20077a6e44cad\"\n",
    "# !aws ec2 terminate-instances --instance-ids \"i-0e4ccb193e3cdcdc8\" \"i-03e1edfe2e3dfbebe\" \"i-097fb433d4ae7cbf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Now let's import some data on which instance types are available, and how much they cost.\n",
    "We will use a subset of the instanceType list to start multiple EC2 instances which we want to compare. We will use the pricing data later on, to compare performance to pricing. "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:hw2/.ipynb_checkpoints/hw2PhilippFirstTry-checkpoint.ipynb
   "execution_count": null,
=======
   "execution_count": 3,
>>>>>>> 2ec9f9959224f60d8f7ccfb3db3641004d4e7a55:hw2/hw2Methods.ipynb
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
<<<<<<< HEAD:hw2/.ipynb_checkpoints/hw2PhilippFirstTry-checkpoint.ipynb
   "outputs": [],
=======
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instanceType</th>\n",
       "      <th>vCPU</th>\n",
       "      <th>ECU</th>\n",
       "      <th>memoryGB</th>\n",
       "      <th>instanceStorage</th>\n",
       "      <th>priceHour</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t3.nano</td>\n",
       "      <td>2</td>\n",
       "      <td>Variable</td>\n",
       "      <td>0.5 GiB</td>\n",
       "      <td>EBS Only</td>\n",
       "      <td>$0.0062 per Hour</td>\n",
       "      <td>general purpose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t3.micro</td>\n",
       "      <td>2</td>\n",
       "      <td>Variable</td>\n",
       "      <td>1 GiB</td>\n",
       "      <td>EBS Only</td>\n",
       "      <td>$0.0125 per Hour</td>\n",
       "      <td>general purpose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t3.small</td>\n",
       "      <td>2</td>\n",
       "      <td>Variable</td>\n",
       "      <td>2 GiB</td>\n",
       "      <td>EBS Only</td>\n",
       "      <td>$0.025 per Hour</td>\n",
       "      <td>general purpose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t3.medium</td>\n",
       "      <td>2</td>\n",
       "      <td>Variable</td>\n",
       "      <td>4 GiB</td>\n",
       "      <td>EBS Only</td>\n",
       "      <td>$0.0499 per Hour</td>\n",
       "      <td>general purpose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t3.large</td>\n",
       "      <td>2</td>\n",
       "      <td>Variable</td>\n",
       "      <td>8 GiB</td>\n",
       "      <td>EBS Only</td>\n",
       "      <td>$0.0998 per Hour</td>\n",
       "      <td>general purpose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>t3.xlarge</td>\n",
       "      <td>4</td>\n",
       "      <td>Variable</td>\n",
       "      <td>16 GiB</td>\n",
       "      <td>EBS Only</td>\n",
       "      <td>$0.1997 per Hour</td>\n",
       "      <td>general purpose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>t3.2xlarge</td>\n",
       "      <td>8</td>\n",
       "      <td>Variable</td>\n",
       "      <td>32 GiB</td>\n",
       "      <td>EBS Only</td>\n",
       "      <td>$0.3994 per Hour</td>\n",
       "      <td>general purpose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>m5.large</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8 GiB</td>\n",
       "      <td>EBS Only</td>\n",
       "      <td>$0.115 per Hour</td>\n",
       "      <td>general purpose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>m5.xlarge</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>16 GiB</td>\n",
       "      <td>EBS Only</td>\n",
       "      <td>$0.23 per Hour</td>\n",
       "      <td>general purpose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>m5.2xlarge</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>32 GiB</td>\n",
       "      <td>EBS Only</td>\n",
       "      <td>$0.461 per Hour</td>\n",
       "      <td>general purpose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>m5.4xlarge</td>\n",
       "      <td>16</td>\n",
       "      <td>70</td>\n",
       "      <td>64 GiB</td>\n",
       "      <td>EBS Only</td>\n",
       "      <td>$0.922 per Hour</td>\n",
       "      <td>general purpose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>m5.8xlarge</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>128 GiB</td>\n",
       "      <td>EBS Only</td>\n",
       "      <td>$1.843 per Hour</td>\n",
       "      <td>general purpose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>m5.12xlarge</td>\n",
       "      <td>48</td>\n",
       "      <td>168</td>\n",
       "      <td>192 GiB</td>\n",
       "      <td>EBS Only</td>\n",
       "      <td>$2.765 per Hour</td>\n",
       "      <td>general purpose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>m5.16xlarge</td>\n",
       "      <td>64</td>\n",
       "      <td>256</td>\n",
       "      <td>256 GiB</td>\n",
       "      <td>EBS Only</td>\n",
       "      <td>$3.686 per Hour</td>\n",
       "      <td>general purpose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>m5.24xlarge</td>\n",
       "      <td>96</td>\n",
       "      <td>337</td>\n",
       "      <td>384 GiB</td>\n",
       "      <td>EBS Only</td>\n",
       "      <td>$5.53 per Hour</td>\n",
       "      <td>general purpose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>m5.metal</td>\n",
       "      <td>96</td>\n",
       "      <td>345</td>\n",
       "      <td>384 GiB</td>\n",
       "      <td>EBS Only</td>\n",
       "      <td>$5.53 per Hour</td>\n",
       "      <td>general purpose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>c5.large</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4 GiB</td>\n",
       "      <td>EBS Only</td>\n",
       "      <td>$0.102 per Hour</td>\n",
       "      <td>compute optimized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>c5.xlarge</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>8 GiB</td>\n",
       "      <td>EBS Only</td>\n",
       "      <td>$0.204 per Hour</td>\n",
       "      <td>compute optimized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>c5.2xlarge</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>16 GiB</td>\n",
       "      <td>EBS Only</td>\n",
       "      <td>$0.408 per Hour</td>\n",
       "      <td>compute optimized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>c5.4xlarge</td>\n",
       "      <td>16</td>\n",
       "      <td>73</td>\n",
       "      <td>32 GiB</td>\n",
       "      <td>EBS Only</td>\n",
       "      <td>$0.816 per Hour</td>\n",
       "      <td>compute optimized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>c5.9xlarge</td>\n",
       "      <td>36</td>\n",
       "      <td>139</td>\n",
       "      <td>72 GiB</td>\n",
       "      <td>EBS Only</td>\n",
       "      <td>$1.836 per Hour</td>\n",
       "      <td>compute optimized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>c5.12xlarge</td>\n",
       "      <td>48</td>\n",
       "      <td>188</td>\n",
       "      <td>96 GiB</td>\n",
       "      <td>EBS Only</td>\n",
       "      <td>$2.448 per Hour</td>\n",
       "      <td>compute optimized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>c5.18xlarge</td>\n",
       "      <td>72</td>\n",
       "      <td>281</td>\n",
       "      <td>144 GiB</td>\n",
       "      <td>EBS Only</td>\n",
       "      <td>$3.672 per Hour</td>\n",
       "      <td>compute optimized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>c5.24xlarge</td>\n",
       "      <td>96</td>\n",
       "      <td>375</td>\n",
       "      <td>192 GiB</td>\n",
       "      <td>EBS Only</td>\n",
       "      <td>$4.896 per Hour</td>\n",
       "      <td>compute optimized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>c5.metal</td>\n",
       "      <td>96</td>\n",
       "      <td>375</td>\n",
       "      <td>192 GiB</td>\n",
       "      <td>EBS Only</td>\n",
       "      <td>$4.896 per Hour</td>\n",
       "      <td>compute optimized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>g4dn.xlarge</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16 GiB</td>\n",
       "      <td>125 GB NVMe SSD</td>\n",
       "      <td>$0.631 per Hour</td>\n",
       "      <td>GPU instances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>g4dn.2xlarge</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32 GiB</td>\n",
       "      <td>225 GB NVMe SSD</td>\n",
       "      <td>$0.902 per Hour</td>\n",
       "      <td>GPU instances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>g4dn.4xlarge</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64 GiB</td>\n",
       "      <td>225 GB NVMe SSD</td>\n",
       "      <td>$1.445 per Hour</td>\n",
       "      <td>GPU instances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>g4dn.8xlarge</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128 GiB</td>\n",
       "      <td>900 GB NVMe SSD</td>\n",
       "      <td>$2.611 per Hour</td>\n",
       "      <td>GPU instances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>g4dn.12xlarge</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>192 GiB</td>\n",
       "      <td>900 GB NVMe SSD</td>\n",
       "      <td>$4.694 per Hour</td>\n",
       "      <td>GPU instances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>g4dn.16xlarge</td>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256 GiB</td>\n",
       "      <td>900 GB NVMe SSD</td>\n",
       "      <td>$5.222 per Hour</td>\n",
       "      <td>GPU instances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>r5.large</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>16 GiB</td>\n",
       "      <td>EBS Only</td>\n",
       "      <td>$0.151 per Hour</td>\n",
       "      <td>memory optimized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>r5.xlarge</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>32 GiB</td>\n",
       "      <td>EBS Only</td>\n",
       "      <td>$0.302 per Hour</td>\n",
       "      <td>memory optimized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>r5.2xlarge</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>64 GiB</td>\n",
       "      <td>EBS Only</td>\n",
       "      <td>$0.605 per Hour</td>\n",
       "      <td>memory optimized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>r5.4xlarge</td>\n",
       "      <td>16</td>\n",
       "      <td>70</td>\n",
       "      <td>128 GiB</td>\n",
       "      <td>EBS Only</td>\n",
       "      <td>$1.21 per Hour</td>\n",
       "      <td>memory optimized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>r5.8xlarge</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>256 GiB</td>\n",
       "      <td>EBS Only</td>\n",
       "      <td>$2.419 per Hour</td>\n",
       "      <td>memory optimized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>r5.12xlarge</td>\n",
       "      <td>48</td>\n",
       "      <td>168</td>\n",
       "      <td>384 GiB</td>\n",
       "      <td>EBS Only</td>\n",
       "      <td>$3.629 per Hour</td>\n",
       "      <td>memory optimized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>r5.16xlarge</td>\n",
       "      <td>64</td>\n",
       "      <td>256</td>\n",
       "      <td>512 GiB</td>\n",
       "      <td>EBS Only</td>\n",
       "      <td>$4.838 per Hour</td>\n",
       "      <td>memory optimized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>r5.24xlarge</td>\n",
       "      <td>96</td>\n",
       "      <td>337</td>\n",
       "      <td>768 GiB</td>\n",
       "      <td>EBS Only</td>\n",
       "      <td>$7.258 per Hour</td>\n",
       "      <td>memory optimized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>r5.metal</td>\n",
       "      <td>96</td>\n",
       "      <td>347</td>\n",
       "      <td>768 GiB</td>\n",
       "      <td>EBS Only</td>\n",
       "      <td>$7.258 per Hour</td>\n",
       "      <td>memory optimized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>r5d.large</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>16 GiB</td>\n",
       "      <td>1 x 75 NVMe SSD</td>\n",
       "      <td>$0.173 per Hour</td>\n",
       "      <td>memory optimized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>r5d.xlarge</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>32 GiB</td>\n",
       "      <td>1 x 150 NVMe SSD</td>\n",
       "      <td>$0.346 per Hour</td>\n",
       "      <td>memory optimized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>r5d.2xlarge</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>64 GiB</td>\n",
       "      <td>1 x 300 NVMe SSD</td>\n",
       "      <td>$0.691 per Hour</td>\n",
       "      <td>memory optimized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>r5d.4xlarge</td>\n",
       "      <td>16</td>\n",
       "      <td>70</td>\n",
       "      <td>128 GiB</td>\n",
       "      <td>2 x 300 NVMe SSD</td>\n",
       "      <td>$1.382 per Hour</td>\n",
       "      <td>memory optimized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>r5d.8xlarge</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>256 GiB</td>\n",
       "      <td>2 x 600 NVMe SSD</td>\n",
       "      <td>$2.765 per Hour</td>\n",
       "      <td>memory optimized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>r5d.12xlarge</td>\n",
       "      <td>48</td>\n",
       "      <td>168</td>\n",
       "      <td>384 GiB</td>\n",
       "      <td>2 x 900 NVMe SSD</td>\n",
       "      <td>$4.147 per Hour</td>\n",
       "      <td>memory optimized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>r5d.16xlarge</td>\n",
       "      <td>64</td>\n",
       "      <td>256</td>\n",
       "      <td>512 GiB</td>\n",
       "      <td>4 x 600 NVMe SSD</td>\n",
       "      <td>$5.53 per Hour</td>\n",
       "      <td>memory optimized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>r5d.24xlarge</td>\n",
       "      <td>96</td>\n",
       "      <td>337</td>\n",
       "      <td>768 GiB</td>\n",
       "      <td>4 x 900 NVMe SSD</td>\n",
       "      <td>$8.294 per Hour</td>\n",
       "      <td>memory optimized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>r5d.metal</td>\n",
       "      <td>96</td>\n",
       "      <td>347</td>\n",
       "      <td>768 GiB</td>\n",
       "      <td>4 x 900 NVMe SSD</td>\n",
       "      <td>$8.294 per Hour</td>\n",
       "      <td>memory optimized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>i3en.large</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>16 GiB</td>\n",
       "      <td>1 x 1250 NVMe SSD</td>\n",
       "      <td>$0.271 per Hour</td>\n",
       "      <td>storage optimized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>i3en.xlarge</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32 GiB</td>\n",
       "      <td>1 x 2500 NVMe SSD</td>\n",
       "      <td>$0.542 per Hour</td>\n",
       "      <td>storage optimized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>i3en.2xlarge</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>64 GiB</td>\n",
       "      <td>2 x 2500 NVMe SSD</td>\n",
       "      <td>$1.085 per Hour</td>\n",
       "      <td>storage optimized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>i3en.3xlarge</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96 GiB</td>\n",
       "      <td>1 x 7500 NVMe SSD</td>\n",
       "      <td>$1.627 per Hour</td>\n",
       "      <td>storage optimized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>i3en.6xlarge</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>192 GiB</td>\n",
       "      <td>2 x 7500 NVMe SSD</td>\n",
       "      <td>$3.254 per Hour</td>\n",
       "      <td>storage optimized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>i3en.12xlarge</td>\n",
       "      <td>48</td>\n",
       "      <td>168</td>\n",
       "      <td>384 GiB</td>\n",
       "      <td>4 x 7500 NVMe SSD</td>\n",
       "      <td>$6.509 per Hour</td>\n",
       "      <td>storage optimized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>i3en.24xlarge</td>\n",
       "      <td>96</td>\n",
       "      <td>337</td>\n",
       "      <td>768 GiB</td>\n",
       "      <td>8 x 7500 NVMe SSD</td>\n",
       "      <td>$13.018 per Hour</td>\n",
       "      <td>storage optimized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>i3en.metal</td>\n",
       "      <td>96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>768 GiB</td>\n",
       "      <td>8 x 7500 NVMe SSD</td>\n",
       "      <td>$13.018 per Hour</td>\n",
       "      <td>storage optimized</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     instanceType  vCPU       ECU memoryGB    instanceStorage  \\\n",
       "0         t3.nano     2  Variable  0.5 GiB           EBS Only   \n",
       "1        t3.micro     2  Variable    1 GiB           EBS Only   \n",
       "2        t3.small     2  Variable    2 GiB           EBS Only   \n",
       "3       t3.medium     2  Variable    4 GiB           EBS Only   \n",
       "4        t3.large     2  Variable    8 GiB           EBS Only   \n",
       "5       t3.xlarge     4  Variable   16 GiB           EBS Only   \n",
       "6      t3.2xlarge     8  Variable   32 GiB           EBS Only   \n",
       "7        m5.large     2        10    8 GiB           EBS Only   \n",
       "8       m5.xlarge     4        16   16 GiB           EBS Only   \n",
       "9      m5.2xlarge     8        37   32 GiB           EBS Only   \n",
       "10     m5.4xlarge    16        70   64 GiB           EBS Only   \n",
       "11     m5.8xlarge    32       128  128 GiB           EBS Only   \n",
       "12    m5.12xlarge    48       168  192 GiB           EBS Only   \n",
       "13    m5.16xlarge    64       256  256 GiB           EBS Only   \n",
       "14    m5.24xlarge    96       337  384 GiB           EBS Only   \n",
       "15       m5.metal    96       345  384 GiB           EBS Only   \n",
       "16       c5.large     2        10    4 GiB           EBS Only   \n",
       "17      c5.xlarge     4        20    8 GiB           EBS Only   \n",
       "18     c5.2xlarge     8        39   16 GiB           EBS Only   \n",
       "19     c5.4xlarge    16        73   32 GiB           EBS Only   \n",
       "20     c5.9xlarge    36       139   72 GiB           EBS Only   \n",
       "21    c5.12xlarge    48       188   96 GiB           EBS Only   \n",
       "22    c5.18xlarge    72       281  144 GiB           EBS Only   \n",
       "23    c5.24xlarge    96       375  192 GiB           EBS Only   \n",
       "24       c5.metal    96       375  192 GiB           EBS Only   \n",
       "25    g4dn.xlarge     4       NaN   16 GiB    125 GB NVMe SSD   \n",
       "26   g4dn.2xlarge     8       NaN   32 GiB    225 GB NVMe SSD   \n",
       "27   g4dn.4xlarge    16       NaN   64 GiB    225 GB NVMe SSD   \n",
       "28   g4dn.8xlarge    32       NaN  128 GiB    900 GB NVMe SSD   \n",
       "29  g4dn.12xlarge    48       NaN  192 GiB    900 GB NVMe SSD   \n",
       "30  g4dn.16xlarge    64       NaN  256 GiB    900 GB NVMe SSD   \n",
       "31       r5.large     2        10   16 GiB           EBS Only   \n",
       "32      r5.xlarge     4        19   32 GiB           EBS Only   \n",
       "33     r5.2xlarge     8        37   64 GiB           EBS Only   \n",
       "34     r5.4xlarge    16        70  128 GiB           EBS Only   \n",
       "35     r5.8xlarge    32       128  256 GiB           EBS Only   \n",
       "36    r5.12xlarge    48       168  384 GiB           EBS Only   \n",
       "37    r5.16xlarge    64       256  512 GiB           EBS Only   \n",
       "38    r5.24xlarge    96       337  768 GiB           EBS Only   \n",
       "39       r5.metal    96       347  768 GiB           EBS Only   \n",
       "40      r5d.large     2        10   16 GiB    1 x 75 NVMe SSD   \n",
       "41     r5d.xlarge     4        19   32 GiB   1 x 150 NVMe SSD   \n",
       "42    r5d.2xlarge     8        37   64 GiB   1 x 300 NVMe SSD   \n",
       "43    r5d.4xlarge    16        70  128 GiB   2 x 300 NVMe SSD   \n",
       "44    r5d.8xlarge    32       128  256 GiB   2 x 600 NVMe SSD   \n",
       "45   r5d.12xlarge    48       168  384 GiB   2 x 900 NVMe SSD   \n",
       "46   r5d.16xlarge    64       256  512 GiB   4 x 600 NVMe SSD   \n",
       "47   r5d.24xlarge    96       337  768 GiB   4 x 900 NVMe SSD   \n",
       "48      r5d.metal    96       347  768 GiB   4 x 900 NVMe SSD   \n",
       "49     i3en.large     2        10   16 GiB  1 x 1250 NVMe SSD   \n",
       "50    i3en.xlarge     4       NaN   32 GiB  1 x 2500 NVMe SSD   \n",
       "51   i3en.2xlarge     8        37   64 GiB  2 x 2500 NVMe SSD   \n",
       "52   i3en.3xlarge    12       NaN   96 GiB  1 x 7500 NVMe SSD   \n",
       "53   i3en.6xlarge    24       NaN  192 GiB  2 x 7500 NVMe SSD   \n",
       "54  i3en.12xlarge    48       168  384 GiB  4 x 7500 NVMe SSD   \n",
       "55  i3en.24xlarge    96       337  768 GiB  8 x 7500 NVMe SSD   \n",
       "56     i3en.metal    96       NaN  768 GiB  8 x 7500 NVMe SSD   \n",
       "\n",
       "           priceHour           category  \n",
       "0   $0.0062 per Hour    general purpose  \n",
       "1   $0.0125 per Hour    general purpose  \n",
       "2    $0.025 per Hour    general purpose  \n",
       "3   $0.0499 per Hour    general purpose  \n",
       "4   $0.0998 per Hour    general purpose  \n",
       "5   $0.1997 per Hour    general purpose  \n",
       "6   $0.3994 per Hour    general purpose  \n",
       "7    $0.115 per Hour    general purpose  \n",
       "8     $0.23 per Hour    general purpose  \n",
       "9    $0.461 per Hour    general purpose  \n",
       "10   $0.922 per Hour    general purpose  \n",
       "11   $1.843 per Hour    general purpose  \n",
       "12   $2.765 per Hour    general purpose  \n",
       "13   $3.686 per Hour    general purpose  \n",
       "14    $5.53 per Hour    general purpose  \n",
       "15    $5.53 per Hour    general purpose  \n",
       "16   $0.102 per Hour  compute optimized  \n",
       "17   $0.204 per Hour  compute optimized  \n",
       "18   $0.408 per Hour  compute optimized  \n",
       "19   $0.816 per Hour  compute optimized  \n",
       "20   $1.836 per Hour  compute optimized  \n",
       "21   $2.448 per Hour  compute optimized  \n",
       "22   $3.672 per Hour  compute optimized  \n",
       "23   $4.896 per Hour  compute optimized  \n",
       "24   $4.896 per Hour  compute optimized  \n",
       "25   $0.631 per Hour      GPU instances  \n",
       "26   $0.902 per Hour      GPU instances  \n",
       "27   $1.445 per Hour      GPU instances  \n",
       "28   $2.611 per Hour      GPU instances  \n",
       "29   $4.694 per Hour      GPU instances  \n",
       "30   $5.222 per Hour      GPU instances  \n",
       "31   $0.151 per Hour   memory optimized  \n",
       "32   $0.302 per Hour   memory optimized  \n",
       "33   $0.605 per Hour   memory optimized  \n",
       "34    $1.21 per Hour   memory optimized  \n",
       "35   $2.419 per Hour   memory optimized  \n",
       "36   $3.629 per Hour   memory optimized  \n",
       "37   $4.838 per Hour   memory optimized  \n",
       "38   $7.258 per Hour   memory optimized  \n",
       "39   $7.258 per Hour   memory optimized  \n",
       "40   $0.173 per Hour   memory optimized  \n",
       "41   $0.346 per Hour   memory optimized  \n",
       "42   $0.691 per Hour   memory optimized  \n",
       "43   $1.382 per Hour   memory optimized  \n",
       "44   $2.765 per Hour   memory optimized  \n",
       "45   $4.147 per Hour   memory optimized  \n",
       "46    $5.53 per Hour   memory optimized  \n",
       "47   $8.294 per Hour   memory optimized  \n",
       "48   $8.294 per Hour   memory optimized  \n",
       "49   $0.271 per Hour  storage optimized  \n",
       "50   $0.542 per Hour  storage optimized  \n",
       "51   $1.085 per Hour  storage optimized  \n",
       "52   $1.627 per Hour  storage optimized  \n",
       "53   $3.254 per Hour  storage optimized  \n",
       "54   $6.509 per Hour  storage optimized  \n",
       "55  $13.018 per Hour  storage optimized  \n",
       "56  $13.018 per Hour  storage optimized  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> 2ec9f9959224f60d8f7ccfb3db3641004d4e7a55:hw2/hw2Methods.ipynb
   "source": [
    "pricedf = pd.read_csv('ec2ondemandprices20200419.csv')\n",
    "pricedf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here, we are making price column numeric. Then, for this initial test we select only the cheapest instances, to prevent spending too much money on something that might not work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "if pricedf['priceHour'].dtype == 'O':\n",
    "    pricedf['priceHour'] = pd.to_numeric(pricedf.priceHour.str.extract('(\\d*\\.?\\d.?\\d.?\\d.)')[0])\n",
    "\n",
    "priceCutOff = 0.5\n",
    "dfTest = pricedf[pricedf['priceHour'] < priceCutOff]\n",
    "\n",
    "typeList = dfTest['instanceType'].tolist()\n",
    "priceList = np.round(dfTest['priceHour'].tolist(),4)\n",
    "print(typeList)\n",
    "print(priceList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### We'll have to set up each instance before running our test\n",
    "Here, we are creating a script that we will run on each instance to set it up. (This is basically copy-pasted from the class materials.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "startup_script = '''git clone https://github.com/fliphilipp/Public-DSC291\n",
    "sudo pip install psutil\n",
    "\n",
    "# run the following if the instance has an SSD that needs to be formatted and mounted.\n",
    "\n",
    "lsblk\n",
    "sudo mkfs.ext4 -E nodiscard -m0 /dev/nvme0n1   #format\n",
    "sudo mkdir /home/ubuntu/spda                   #make root for mounting\n",
    "sudo mount -o discard /dev/nvme0n1 /home/ubuntu/spda # mount\n",
    "ln -s /home/ubuntu/spda scratch                #create local link\n",
    "sudo chmod a+rwx scratch                       # make read/write-able\n",
    "lsblk'''\n",
    "\n",
    "theFile = open('startup.sh','w') \n",
    "theFile.write(startup_script) \n",
    "theFile.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# make sure this worked\n",
    "!cat startup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Python wrapper for aws-jupyter\n",
    "To use aws-jupyter effectively from a notebook, we are adding some code that makes it easier to run commands from here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def run_command(command,debug=False):\n",
    "    if debug:\n",
    "        print('running ',command)\n",
    "    p=subprocess.Popen(command.split(), stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    out=p.communicate()\n",
    "    stdout=out[0].decode()\n",
    "    stderr=out[1].decode()\n",
    "    outputs={\"stderr\":stderr,\n",
    "             \"stdout\":stdout}\n",
    "    if debug:\n",
    "        print(outputs)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class aws_jupyter:\n",
    "    \"\"\"\n",
    "    A python wrapper around the script **aws-jupyter**\n",
    "    \"\"\"\n",
    "    \n",
    "    def check(self):\n",
    "        \"\"\"\n",
    "        Check on the status of the ec2 instance\n",
    "        Returns status\n",
    "        -------\n",
    "        0 = No instance running under this name \n",
    "        \n",
    "        1 = instance in the process of starting up\n",
    "        \n",
    "        2 = instance available        \n",
    "        \n",
    "        -1 = Status could not be parsed\n",
    "        \"\"\"\n",
    "        check_cmd = \"aws-jupyter check --name %s\"%self.name\n",
    "        self.decoded=run_command(check_cmd)\n",
    "        stdout=self.decoded['stdout']\n",
    "        if('The Jupyter Notebook is running on the cluster at the address below.' in stdout):\n",
    "            print(stdout)\n",
    "            return 2\n",
    "        elif(\"No instance found in the cluster\" in stdout):\n",
    "            return 0\n",
    "        elif(\"Cluster is not ready. Please check again later.\" in stdout):\n",
    "            return 1\n",
    "        else:\n",
    "            print(\" ...did not recognize check status\")\n",
    "            # print(stdout)\n",
    "            return -1\n",
    "\n",
    "    def run(self,scriptname,files=[],credentials=\"\",waitforoutput=True,printoutput=False): \n",
    "        \"\"\"\n",
    "        Run a local script on the remote instance\n",
    "        Parameters\n",
    "        ----------\n",
    "        scriptname : TYPE\n",
    "            DESCRIPTION.\n",
    "        files : TYPE, optional\n",
    "            DESCRIPTION. The default is [].\n",
    "        credentials : TYPE\n",
    "            DESCRIPTION.\n",
    "        waitforoutput : TYPE, optional\n",
    "            DESCRIPTION. The default is True.\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "        \"\"\"\n",
    "            \n",
    "        running_cmd = \"aws-jupyter run -s {script}\"\n",
    "        runcmd = running_cmd.format(script=scriptname)\n",
    "        if len(files)>0:\n",
    "            runcmd += \" --files\"\n",
    "            for i in range(len(files)):\n",
    "                runcmd += \" {fn}\".format(fn=files[i])\n",
    "        if waitforoutput:\n",
    "            runcmd += \" --output\"\n",
    "        print(\"running command: {runcmd}\".format(runcmd=runcmd))\n",
    "        out = run_command(runcmd,debug=False)\n",
    "        if printoutput:\n",
    "            print(out['stdout'])\n",
    "            print(out['stderr'])\n",
    "\n",
    "    def retrieve():\n",
    "        \"\"\" call aws-jupyter retrieve\"\"\"\n",
    "        return\n",
    "    \n",
    "    def terminate(self,printoutput=False):\n",
    "        \"\"\" call aws-jupyter terminate\"\"\"\n",
    "        term_cmd = \"yes | aws-jupyter terminate --name %s\" % self.name\n",
    "        print(\"terminate instance: {term_cmd}\".format(term_cmd=term_cmd))\n",
    "        out = run_command(term_cmd)\n",
    "        if printoutput:\n",
    "            print(out['stdout'])\n",
    "            print(out['stderr'])\n",
    "            \n",
    "    def __init__(self,name='instance',count=1,_type='t3.large',spot=0):\n",
    "        \"\"\"\n",
    "        Create a cluster of instances on ec2\n",
    "        Parameters\n",
    "        ----------\n",
    "        name : TYPE, optional\n",
    "            DESCRIPTION. The default is 'instance'.\n",
    "        count : TYPE, optional\n",
    "            DESCRIPTION. The default is 1.\n",
    "        _type : TYPE, optional\n",
    "            DESCRIPTION. The default is 't3.large'.\n",
    "        spot : TYPE, optional\n",
    "            DESCRIPTION. The default is 0.\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "        \"\"\"\n",
    "        self.name=name\n",
    "        status=self.check()\n",
    "        if status==1:\n",
    "            print(\"cluster %s not ready yet\"%self.name)\n",
    "            return\n",
    "        elif status==2:\n",
    "            print(\"cluster running\")\n",
    "            return\n",
    "\n",
    "        create_cmd = \"aws-jupyter create -c {count} --name {name} --type {_type}\"\n",
    "        command=create_cmd.format(count=count,name=name,_type=_type)\n",
    "        if spot>0:\n",
    "            command.append(\" --spot %4.2f\"%spot)\n",
    "        out=run_command(command)\n",
    "        print(\"initiated instance:\",command)\n",
    " \n",
    "        i=0; wait_period=10\n",
    "        while True:\n",
    "            status=self.check()\n",
    "            if status==2:\n",
    "                # print(stdout)\n",
    "                break\n",
    "            print('\\r check',i*wait_period,end='')\n",
    "            i+=1\n",
    "            sleep(wait_period)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Jake]: This is where we can run the scripts I wrote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for typeL in typeList:\n",
    "    \n",
    "    !aws-jupyter create -c 1 --name typeL\n",
    "    time.sleep(30) # wait for aws to configure the instance\n",
    "    !aws-jupyter check --name typeL\n",
    "    ## The below directory should be the git repository. the remote directory \"./\" is \"/home/ubuntu/hw2\" on the AWS system\n",
    "    !aws-jupyter send-dir --local \"/home/jakemdaly/Documents/courses/dsc-291/TeamGitRepo/Public-DSC291/hw2/\" --remote ./\n",
    "    \n",
    "    !aws-jupyter run --script ./RunFileGenerator.sh #NOTE: This is the part we need to figure out :(\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws-jupyter retrieve --remote /home/ubuntu/workspace/1KB.txt --local ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A test script to run on each instance\n",
    "\n",
    "Here, we are defining a test script that we will be running on each instance. The calculations to be done are timed a hundred times, and the results are written to a pickle file. \n",
    "\n",
    "For this test, we are just running a quick and simple task (finding the 100,000th Fibonacci number recursively). For our actual experiment, this script is more involved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "program_to_run = '''#!/usr/bin/env python3\n",
    "\n",
    "import numpy as np\n",
    "from time import time\n",
    "from os.path import isfile,isdir\n",
    "from os import mkdir,chdir,getcwd\n",
    "import pickle as pk\n",
    "\n",
    "times = []\n",
    "nTrials = 100\n",
    "nFibonacci = 10**5\n",
    "\n",
    "# a dumb random computational task, on which to compare instances\n",
    "inst_starttime = time()\n",
    "for k in range(nTrials):\n",
    "    starttime = time()\n",
    "    fibonacci_previous = 1\n",
    "    fibonacci_current = 1\n",
    "    for i in range(2,nFibonacci):\n",
    "        fibonacci_next = fibonacci_previous + fibonacci_current\n",
    "        fibonacci_previous = fibonacci_current\n",
    "        fibonacci_current = fibonacci_next\n",
    "    DT = time() - starttime\n",
    "    times.append(DT)\n",
    "print(time() - inst_starttime)\n",
    "    \n",
    "#hist(times,bins=50)\n",
    "exec_dir = getcwd()\n",
    "log_dir = exec_dir + '/measurement_logs/'\n",
    "if not isdir(log_dir):\n",
    "    mkdir(log_dir)\n",
    "fn = log_dir + 'stats.pkl'\n",
    "with open(fn,'wb') as times_pkl:\n",
    "    pk.dump(times,times_pkl,protocol=pk.HIGHEST_PROTOCOL)'''\n",
    "\n",
    "theFile = open('ec2testFibonacci.py','w') \n",
    "theFile.write(program_to_run) \n",
    "theFile.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Before we start, let's check which instances we will actually be using.\n",
    "We can also further make the list shorter here, if we are just trying to see if this notebook works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# if you want to just try, say, 3 different ones for testing\n",
    "# typeList = typeList[0:3]\n",
    "typeList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Now lets start all instances in the list and run our timed experiment multiple times!\n",
    "This is where things actually happen. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# create a directory in which we will collect test results from different instance types\n",
    "remotedir = 'from_remote'\n",
    "if not isdir(remotedir):\n",
    "    mkdir(remotedir)\n",
    "\n",
    "# now loop through all instance types that we want to test, and actually run the test on them\n",
    "for thisType in typeList:\n",
    "    thisName = \"h2\" + thisType.replace('.','')\n",
    "    \n",
    "    # initiate instance and run startup\n",
    "    thisInst = aws_jupyter(name=thisName, count=1, _type=thisType)\n",
    "    thisInst.run(scriptname='startup.sh',printoutput=True)\n",
    "    \n",
    "    # run the test script\n",
    "    thisInst.run(scriptname='ec2testFibonacci.py',printoutput=True)\n",
    "    \n",
    "    # retrieve files\n",
    "    !sleep 120\n",
    "    !aws-jupyter retrieve --remote /home/ubuntu/workspace/measurement_logs/stats.pkl --local from_remote/\n",
    "    new_fn = 'from_remote/stats_' + thisType.replace('.','-') + '.pkl'\n",
    "    !mv from_remote/worker-0/stats.pkl $new_fn\n",
    "    \n",
    "    # terminate instances\n",
    "    # thisInst.terminate(printoutput=True)  # <--- somehow this doesn't work!\n",
    "    !yes | aws-jupyter terminate --name $thisInst.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Print out a list of our instances again\n",
    "To make sure we've terminated them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# , to make sure we've terminated them\n",
    "!aws ec2 describe-instances \\\n",
    "    --query 'Reservations[*].Instances[*].{Type:InstanceType,\\\n",
    "                                           LaunchTime:LaunchTime,\\\n",
    "                                           Instance:InstanceId,\\\n",
    "                                           KeyName:KeyName,\\\n",
    "                                           State:State.Name,\\\n",
    "                                           Name:Tags[?Key==`cluster-name`]|[0].Value}' \\\n",
    "    --output table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Now, get all the collected data back into this notebook\n",
    "Here, we create a pandas dataframe with all the data collected from the different types of instances. We need to collect the data from all the different files that were sent back to us from the different instances we've created.\n",
    "\n",
    "We can print the first few lines of the dataframe to see if the data looks about right. \n",
    "\n",
    "*Here, something must have gone wrong on the instance of type **c5.large** that we had created. The output logs (which were deleted because they contained our AWS credentials) seem to indicate that the ssh connection failed when trying to retrieve the file with the results.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns = typeList)\n",
    "for thisType in typeList:\n",
    "    filename = 'from_remote/stats_' + thisType.replace('.','-') + '.pkl'\n",
    "    if isfile(filename):\n",
    "        infile = open(filename,'rb')\n",
    "        thisData = pk.load(infile)\n",
    "        infile.close()\n",
    "        results[thisType] = thisData\n",
    "\n",
    "# display the top of the dataframe\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Now, we can finally examine the data!\n",
    "Here, we are just creating a boxplot of the execution times by instance type. We see that the (cheap) instances that we tested all needed on average between 0.12 to 0.24 seconds to determine the 100,00th Fibonacci number recursively. The fastest instance types here are the compute optimized **c5.xlarge** and **c5.2xlarge**, and the memory optimized **r5d.xlarge**. \n",
    "\n",
    "Not surprisingly, these faster instances were also some of the comparatively more expensive ones amongst our set of types. So is it actually worth it paying that higher price to cut the execution time down?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bp1 = results.boxplot(rot=90)\n",
    "bp1.set_title('execution times on different instance types')\n",
    "bp1.set_ylabel('execution time in seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cost-effectiveness\n",
    "Here, we multiply the time the computations took by the hourly price of the instance to see how much the computation actually cost us on each type of instance. *(the numbers are very low, since all prices were <$0.50/hr and computation times were less than a second...)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "byPrice = pd.DataFrame(columns = typeList)\n",
    "for i, thisType in enumerate(typeList):\n",
    "    byPrice[thisType] = priceList[i] * (results[thisType] / 3600)\n",
    "byPrice.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Now let's see how adjusting by price changes our perception of instance performance!\n",
    "Now we see that for the same task, <span style=\"color:red\">the least powerful instance types were actually much more efficient</span> than the more powerful ones in terms of total cost!\n",
    "\n",
    "So, if you have a lot of time and are really just interested in recursively calculating Fibonacci numbers, then you should do so on a **t3.nano** instance! \n",
    "\n",
    "We assume that this price effectiveness will change when you do more complex tasks, such as moving large files between S3 and EC2 instances. This is why the second notebook in our submission for homework 2 is testing this scenario, focussing more on the analysis of the results than on the methods of how to get things running. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bp2 = byPrice.boxplot(rot=90)\n",
    "bp2.set_title('cost-effectiveness of different instance types')\n",
    "bp2.set_ylabel('price for execution time of the script')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# To view this notebook as slides\n",
    "!jupyter nbconvert hw2psa.ipynb --to slides --post serve"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
