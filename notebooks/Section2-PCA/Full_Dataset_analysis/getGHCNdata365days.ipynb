{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get NOAA ghcn/daily/by_year into parquet on S3\n",
    "\n",
    "**How to process the new NOAA data (from Yoav)**\n",
    "\n",
    "*Input:* A dataframe with columns: `Station, Year, day-in-year, measurement type, value`\n",
    "1. Translate Dataframe into RDD of rows\n",
    "2. Map into key-value RDD with the format `key=(Station,year, measurement)  value=[(day-of-year, value)]`\n",
    "3. Reduce by key: take the union\n",
    "4. Results in an RDD of the form: `key=(Station,year, measurement) value=[(....),(....)  ]`\n",
    "5. Translate the RDD into a dataframe: map value list into a 365 array, pack into bytearray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished standard imports\n",
      "dict_items([('spark.executor.cores', '1'), ('spark.cores.max', '4'), ('spark.app.name', 'Weather_PCA'), ('spark.executor.memory', '3g'), ('spark.logConf', 'True'), ('spark.default.parallelism', '10')])\n",
      "started SparkContext and SQLContext in 14.48 seconds\n",
      "loaded weather.parquet in 9.07 seconds\n",
      "loaded stations.parquet in 0.21 seconds\n",
      "registered dataframes as tables in 0.21 seconds\n"
     ]
    }
   ],
   "source": [
    "from Startup import *\n",
    "from pyspark.sql.types import *\n",
    "sc.stop()\n",
    "sc = SparkContext(appName=\"CSV2Parquet\")\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the .csv files from NOAA s3 bucket and put into data fame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.15 s, sys: 204 ms, total: 2.35 s\n",
      "Wall time: 9.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "startYear = 1763  # data starts in 1763\n",
    "endYear = 2020  # data (currently ends in 2020)\n",
    "\n",
    "# set schema for import from csv\n",
    "schemaString = \"id year_date element data_value\"\n",
    "schema = StructType([StructField(field_name, StringType(), True) for field_name in schemaString.split()])\n",
    "\n",
    "# the s3 bucket noaa-ghcn-pds/csv/ contains all of the observations from 1763 to the present organized in .csv files\n",
    "# loop through all years \n",
    "allYears = np.arange(startYear,endYear+1)\n",
    "for yr in allYears:\n",
    "    fn = \"s3://noaa-ghcn-pds/csv/\" + str(yr) + \".csv\"\n",
    "    dt = sc.textFile(fn).map(lambda l: l.split(\",\")).map(lambda p: ([x.strip() for x in p[0:4]]))\n",
    "    schemaDT = sqlContext.createDataFrame(dt, schema)\n",
    "    if yr == allYears[0]:\n",
    "        df = schemaDT\n",
    "    else:\n",
    "        df = df.union(schemaDT)\n",
    "        \n",
    "# register table for querying\n",
    "df.createOrReplaceTempView(\"ghcnd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query for data, and specify if the year is a leap year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 197 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# cast values to appropriate types and include whether year is leap year or not\n",
    "qry = \"\"\"\n",
    "SELECT id AS Station,\n",
    "       CAST(SUBSTRING(year_date, 1, 4) AS SMALLINT) AS Year,\n",
    "       DAYOFYEAR(TO_DATE(year_date,'yyyyMMdd')) AS Day,\n",
    "       NOT ISNULL(TO_DATE(CONCAT(SUBSTRING(year_date, 1, 4), '0229'),'yyyyMMdd')) AS isleapyear,\n",
    "       element AS Measurement,\n",
    "       CAST(data_value AS FLOAT) AS Value\n",
    "FROM ghcnd\"\"\"\n",
    "raw_data = sqlContext.sql(qry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data into [Station, Year, Measurement, Value by Day of Year] format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 ms, sys: 4 ms, total: 12 ms\n",
      "Wall time: 5.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# define function for mapping (day-of-year, value) pairs into 365-day array\n",
    "def putIntoArray(x):\n",
    "    arr = [None] * 366  # initialize list\n",
    "    for pair in x[1]:\n",
    "        arr[pair[0]-1] = pair[1]  # set the (dayOfYear-1)-th entry to the corresponding value\n",
    "    if x[0][3]:\n",
    "        del arr[59]  # delete feb 29 for leap year\n",
    "    else:\n",
    "        del arr[365]  # delete day 366 for non leap year\n",
    "        print('toss last day')\n",
    "    return (x[0][0], x[0][1], x[0][2], arr)\n",
    "\n",
    "# 1. Translate Dataframe into RDD of rows\n",
    "arr_rdd = (raw_data.rdd\n",
    "           # 2. Map into key-value RDD with the format `key=(Station,year, measurement)  value=[(day-of-year, value)]`\n",
    "           .map(lambda x: ((x[0],x[1],x[4],x[3]),[(x[2],x[5])]))\n",
    "           # 3. Reduce by key: take the union\n",
    "           # 4. Results in an RDD of the form: `key=(Station,year, measurement) value=[(....),(....)  ]`\n",
    "           .reduceByKey(lambda a, b: a + b)\n",
    "           # 5. Translate the RDD into a dataframe: map value list into a 365 array, pack into bytearray\n",
    "           .map(putIntoArray))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a dataframe from the RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 ms, sys: 0 ns, total: 12 ms\n",
      "Wall time: 23 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "schemaString = \"Station Year Measurement Values\"\n",
    "typeList = [StringType(), IntegerType(), StringType(), ArrayType(DoubleType())]\n",
    "schema = StructType([StructField(field_name, typeList[i], True) for i,field_name in enumerate(schemaString.split())])\n",
    "arr_df = sqlContext.createDataFrame(arr_rdd,schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to a .parquet file on s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.16 s, sys: 104 ms, total: 1.26 s\n",
      "Wall time: 3h 18min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "arr_df.write.parquet(\"s3://philipp-ghcnd/GHCNDby_year.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test by loading data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+-----------+--------------------+\n",
      "|    Station|Year|Measurement|              Values|\n",
      "+-----------+----+-----------+--------------------+\n",
      "|USC00369050|2015|       WT11|[,,, 1.0,,,,,,,,,...|\n",
      "|USW00023275|1954|       SNOW|[,,,,,,,,,,,,,,,,...|\n",
      "|USC00204954|1936|       PRCP|[0.0, 147.0, 0.0,...|\n",
      "|USS0007K02S|1979|       PRCP|[0.0, 25.0, 0.0, ...|\n",
      "|USC00273177|1929|       PRCP|[117.0, 38.0, 0.0...|\n",
      "|CA007056200|1973|       PRCP|[48.0, 0.0, 0.0, ...|\n",
      "|US1MAPL0023|2017|       WESF|[,,,,, 36.0,,,,,,...|\n",
      "|IN011360600|1922|       PRCP|[97.0, 168.0, 0.0...|\n",
      "|ASN00092083|1973|       PRCP|[0.0, 0.0, 0.0, 0...|\n",
      "|ASN00023708|1918|       PRCP|[0.0, 0.0, 0.0, 0...|\n",
      "|USC00306774|1991|       WT11|[,,,,,,,,,,,,,,,,...|\n",
      "|USC00292820|2020|       MDPR|[,,,,,,,,,,,,,,,,...|\n",
      "|USC00238524|1984|       DAPR|[,,,,,,,,,,,,,,,,...|\n",
      "|USC00349760|2009|       WT05|[,,,,,,,,,,,,,,,,...|\n",
      "|USC00148563|1963|       SNWD|[0.0, 0.0, 0.0, 0...|\n",
      "|GMM00010253|1970|       SNWD|[80.0, 70.0, 120....|\n",
      "|MXN00015076|1967|       TMIN|[11.0, 0.0, -17.0...|\n",
      "|USC00027281|1948|       TMIN|[-17.0, -22.0, -2...|\n",
      "|US1TNRD0035|2007|       SNOW|[,,,,,,,,,,,,,,,,...|\n",
      "|USC00242273|1924|       SNOW|[0.0, 0.0, 0.0, 0...|\n",
      "+-----------+----+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 26.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "s3Data = sqlContext.sql(\"SELECT * FROM parquet.`s3://philipp-ghcnd/GHCNDby_year.parquet`\")\n",
    "s3Data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 19.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12346092"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "s3Data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
